{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Return on Investment (ROI)"
      ],
      "metadata": {
        "id": "3O6wh1NBfAFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To estimate the Return on Investment (ROI) for property improvements using an ANN, we need to set up a structured process. Here’s a step-by-step approach:\n",
        "\n",
        "Step 1: Define the ROI Variable\n",
        "Since ROI isn’t likely to be present directly in the dataset, you would typically calculate it based on:\n",
        "\n",
        "Historical data on property improvements: If available, use the increase in SalePrice after certain improvements to calculate ROI.\n",
        "Expert assumptions: Define typical ROI based on common property improvement projects (e.g., adding a bedroom, remodeling bathrooms) using real estate industry standards.\n",
        "For simplicity, let’s assume we have historical data that allows us to define ROI as follows:\n",
        "\n",
        "ROI\n",
        "=\n",
        "Expected SalePrice Increase\n",
        "Improvement Cost\n",
        "ROI=\n",
        "Improvement Cost\n",
        "Expected SalePrice Increase\n",
        "​\n",
        "\n",
        "For this example, we’ll create a synthetic ROI column based on some feature combinations and hypothetical values.\n",
        "\n",
        "Step 2: Prepare the Dataset for ROI Prediction\n",
        "We’ll select features relevant to estimating ROI, such as:\n",
        "\n",
        "Property Value Features: TotalValue, BuildingValue, LandValue\n",
        "Property Characteristics: Bedrooms, FullBath, HalfBath, Acreage, YearBuilt\n",
        "We’ll then preprocess the data and train an ANN to predict ROI.\n",
        "\n",
        "Step 3: Build and Train the ANN Model\n",
        "We’ll design a regression ANN model with a linear output layer to predict ROI as a continuous variable.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Explanation of Key Steps\n",
        "Synthetic ROI Generation: We generated a hypothetical ROI based on the expected increase in SalePrice relative to an assumed improvement cost.\n",
        "Feature Selection: Relevant features were chosen to capture the impact of property characteristics and value components on ROI.\n",
        "ANN Model: A regression model with a linear output layer predicts ROI as a continuous value.\n",
        "Model Evaluation: We evaluate the model on the test set to check the accuracy in predicting ROI."
      ],
      "metadata": {
        "id": "QPtBq1nyeycV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load data\n",
        "nashville_data = pd.read_csv('Nashville_Housing_ML.csv')\n",
        "\n",
        "# Step 1: Create a synthetic ROI column for demonstration purposes\n",
        "nashville_data['ImprovementCost'] = nashville_data['Bedrooms'] * 10000 + nashville_data['FullBath'] * 5000\n",
        "nashville_data['ExpectedSalePriceIncrease'] = nashville_data['BuildingValue'] * 0.1  # Hypothetical increase\n",
        "nashville_data['ROI'] = nashville_data['ExpectedSalePriceIncrease'] / nashville_data['ImprovementCost']\n",
        "\n",
        "# Drop rows where ImprovementCost might be zero to avoid division errors\n",
        "nashville_data = nashville_data[nashville_data['ImprovementCost'] > 0]\n",
        "\n",
        "# Convert 'YearBuilt' to a datetime format and extract the year\n",
        "nashville_data['YearBuilt'] = pd.to_datetime(nashville_data['YearBuilt'], errors='coerce').dt.year\n",
        "\n",
        "# Drop any remaining rows with NaN values in 'YearBuilt'\n",
        "nashville_data = nashville_data.dropna(subset=['YearBuilt'])\n",
        "\n",
        "# Select relevant features for predicting ROI\n",
        "selected_features = ['TotalValue', 'BuildingValue', 'LandValue', 'Bedrooms', 'FullBath', 'HalfBath', 'Acreage', 'YearBuilt']\n",
        "X = nashville_data[selected_features].values\n",
        "y = nashville_data['ROI'].values\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Step 3: Build the ANN model\n",
        "ann = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=16, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1, activation='linear')  # Linear output for regression\n",
        "])\n",
        "\n",
        "# Compile the model with a smaller learning rate\n",
        "ann.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "ann.fit(X_train, y_train, batch_size=32, epochs=50, callbacks=[early_stopping])\n",
        "\n",
        "# Step 4: Evaluate the model and make predictions\n",
        "test_loss, test_mae = ann.evaluate(X_test, y_test)\n",
        "print(f\"Test MAE: {test_mae}\")\n",
        "\n",
        "# Predict ROI on the test set\n",
        "predictions = ann.predict(X_test)\n",
        "\n",
        "# Display some sample predictions\n",
        "for i in range(5):\n",
        "    print(f\"Predicted ROI: {predictions[i][0]:.2f}, Actual ROI: {y_test[i]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmI6vrbCcgOM",
        "outputId": "9f6bf242-e476-4fe8-fdf1-8e430b5f3dba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-87f24e8b15fc>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  nashville_data['YearBuilt'] = pd.to_datetime(nashville_data['YearBuilt'], errors='coerce').dt.year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.0594 - mae: 0.1562\n",
            "Epoch 2/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0217 - mae: 0.0651\n",
            "Epoch 3/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0076 - mae: 0.0379\n",
            "Epoch 4/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0055 - mae: 0.0306\n",
            "Epoch 5/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0296\n",
            "Epoch 6/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0039 - mae: 0.0232\n",
            "Epoch 7/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0076 - mae: 0.0241\n",
            "Epoch 8/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0052 - mae: 0.0208\n",
            "Epoch 9/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0061 - mae: 0.0218\n",
            "Epoch 10/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0047 - mae: 0.0186\n",
            "Epoch 11/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - mae: 0.0182\n",
            "Epoch 12/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0023 - mae: 0.0168\n",
            "Epoch 13/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0017 - mae: 0.0153\n",
            "Epoch 14/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0019 - mae: 0.0165\n",
            "Epoch 15/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0153\n",
            "Epoch 16/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0013 - mae: 0.0141\n",
            "Epoch 17/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0142\n",
            "Epoch 18/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0137\n",
            "Epoch 19/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0013 - mae: 0.0125\n",
            "Epoch 20/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0013 - mae: 0.0128\n",
            "Epoch 21/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0134\n",
            "Epoch 22/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0131\n",
            "Epoch 23/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0119\n",
            "Epoch 24/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0125\n",
            "Epoch 25/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0122\n",
            "Epoch 26/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.4531e-04 - mae: 0.0106\n",
            "Epoch 27/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0060 - mae: 0.0146\n",
            "Epoch 28/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0108\n",
            "Epoch 29/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.3057e-04 - mae: 0.0102\n",
            "Epoch 30/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.5325e-04 - mae: 0.0102\n",
            "Epoch 31/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.5923e-04 - mae: 0.0099\n",
            "Epoch 32/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6.8126e-04 - mae: 0.0102\n",
            "Epoch 33/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.9401e-04 - mae: 0.0103\n",
            "Epoch 34/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0013 - mae: 0.0110\n",
            "Epoch 35/50\n",
            "\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.2389e-04 - mae: 0.0100\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.5878e-04 - mae: 0.0107\n",
            "Test MAE: 0.010867545381188393\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Predicted ROI: 0.33, Actual ROI: 0.33\n",
            "Predicted ROI: 0.26, Actual ROI: 0.25\n",
            "Predicted ROI: 0.34, Actual ROI: 0.31\n",
            "Predicted ROI: 0.43, Actual ROI: 0.42\n",
            "Predicted ROI: 0.71, Actual ROI: 0.70\n"
          ]
        }
      ]
    }
  ]
}