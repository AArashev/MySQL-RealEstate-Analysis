{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Data Type and Transformation Challenges\n",
        "Challenge: SalePrice was initially in an object (string) format, causing issues in model compatibility and scaling.\n",
        "Solution: We converted SalePrice to a numeric type and applied a log transformation (np.log1p) to stabilize its variance. This transformation compresses the wide range of house prices, making it easier for the model to train.\n",
        "2. Feature Selection\n",
        "Challenge: Not all features in the dataset were equally useful. Some features (like YearBuilt, LandUse) had low correlation with SalePrice, which could introduce noise.\n",
        "Solution: We identified and retained only the high-correlation features (TotalValue, LandValue, BuildingValue, FullBath, Bedrooms, Acreage) to improve the model's focus on relevant information.\n",
        "3. Categorical Encoding\n",
        "Challenge: Categorical features (LandUse, SoldAsVacant) needed encoding for the neural network, as it requires numerical input.\n",
        "Solution: We applied One-Hot Encoding for categorical columns, which allowed us to treat these features without implying any ordinal relationship.\n",
        "4. Scaling\n",
        "Challenge: Neural networks are sensitive to feature scales, so unscaled data could lead to poor convergence.\n",
        "Solution: We used StandardScaler to normalize the numerical features in X, which helps the model learn more effectively.\n",
        "5. Model Convergence and High MAE\n",
        "Challenge: Initial model training showed very high Mean Absolute Error (MAE) and unstable learning, possibly due to the learning rate being too high.\n",
        "Solution: We progressively reduced the learning rate, finally setting it to 0.00001 for more stable convergence. This adjustment improved the training stability and reduced MAE significantly over successive epochs.\n",
        "6. Interpreting Predictions on Original Scale\n",
        "Challenge: Since we log-transformed SalePrice, we had to carefully interpret predictions on the original scale.\n",
        "Solution: After model predictions, we applied the inverse transformation (np.expm1) to convert predictions back to their original scale, allowing us to compare directly with actual prices.\n",
        "7. High Discrepancies in Predictions (After Inverse Transformation)\n",
        "Challenge: Despite a low MAE in the transformed space, predictions on the original scale showed significant discrepancies for high-value properties.\n",
        "Solution: We suggested further adjustments like trying alternative transformations (e.g., quantile transformation), experimenting with different loss functions (e.g., MAPE), and considering ensemble models like XGBoost for potentially better handling of the price range.\n",
        "Summary of Key Changes\n",
        "Converted SalePrice to numeric and applied log transformation.\n",
        "Selected high-correlation features and encoded categorical data.\n",
        "Scaled features with StandardScaler.\n",
        "Tuned the model’s learning rate to improve convergence.\n",
        "Interpreted predictions by applying the inverse of the log transformation.\n",
        "These steps collectively improved the model's performance and addressed the initial challenges effectively. Let me know if you'd like more details on any specific step!"
      ],
      "metadata": {
        "id": "74tr3Vvca7ls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB9Re_5uZngN",
        "outputId": "f00c0989-aa36-48e3-eb5d-a6bded3d2efd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 144.4910 - mae: 11.9862\n",
            "Epoch 2/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 137.4883 - mae: 11.6913\n",
            "Epoch 3/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 128.0585 - mae: 11.2747\n",
            "Epoch 4/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 115.9877 - mae: 10.7172\n",
            "Epoch 5/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 101.1749 - mae: 9.9842\n",
            "Epoch 6/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 86.2364 - mae: 9.1640\n",
            "Epoch 7/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 72.9616 - mae: 8.3346\n",
            "Epoch 8/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 59.5533 - mae: 7.4372\n",
            "Epoch 9/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 49.3616 - mae: 6.5431\n",
            "Epoch 10/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 39.4645 - mae: 5.6423\n",
            "Epoch 11/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 32.0415 - mae: 4.8929\n",
            "Epoch 12/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 26.3366 - mae: 4.3242\n",
            "Epoch 13/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 22.6619 - mae: 3.9124\n",
            "Epoch 14/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 20.1711 - mae: 3.6639\n",
            "Epoch 15/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 19.2563 - mae: 3.4285\n",
            "Epoch 16/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 17.7295 - mae: 3.2406\n",
            "Epoch 17/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16.1008 - mae: 3.0990\n",
            "Epoch 18/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 15.6000 - mae: 2.9406\n",
            "Epoch 19/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 14.1535 - mae: 2.8116\n",
            "Epoch 20/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 12.9614 - mae: 2.6571\n",
            "Epoch 21/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 12.1524 - mae: 2.5656\n",
            "Epoch 22/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 11.2379 - mae: 2.4838\n",
            "Epoch 23/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10.0612 - mae: 2.3416\n",
            "Epoch 24/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.7418 - mae: 2.2633\n",
            "Epoch 25/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 10.4545 - mae: 2.1675\n",
            "Epoch 26/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.7288 - mae: 2.1100\n",
            "Epoch 27/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.4534 - mae: 1.9833\n",
            "Epoch 28/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.3325 - mae: 1.9261\n",
            "Epoch 29/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.0880 - mae: 1.8600\n",
            "Epoch 30/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.2789 - mae: 1.7576\n",
            "Epoch 31/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.9374 - mae: 1.6852\n",
            "Epoch 32/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.6108 - mae: 1.5926\n",
            "Epoch 33/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.0608 - mae: 1.5443\n",
            "Epoch 34/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.5746 - mae: 1.4578\n",
            "Epoch 35/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.1739 - mae: 1.3954\n",
            "Epoch 36/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.0960 - mae: 1.3388\n",
            "Epoch 37/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.9050 - mae: 1.2894\n",
            "Epoch 38/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.4305 - mae: 1.2199\n",
            "Epoch 39/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.3357 - mae: 1.1823\n",
            "Epoch 40/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.7325 - mae: 1.1119\n",
            "Epoch 41/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.7411 - mae: 1.0745\n",
            "Epoch 42/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.5563 - mae: 1.0461\n",
            "Epoch 43/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.3448 - mae: 0.9919\n",
            "Epoch 44/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.3761 - mae: 0.9683\n",
            "Epoch 45/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.2635 - mae: 0.9419\n",
            "Epoch 46/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9991 - mae: 0.8886\n",
            "Epoch 47/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.7872 - mae: 0.8554\n",
            "Epoch 48/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.6138 - mae: 0.8254\n",
            "Epoch 49/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6367 - mae: 0.8021\n",
            "Epoch 50/50\n",
            "\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.5187 - mae: 0.7733\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load and preprocess data\n",
        "nashville_data = pd.read_csv('Nashville_Housing_ML.csv')\n",
        "\n",
        "# Apply log transformation to SalePrice for stability\n",
        "nashville_data['SalePrice'] = np.log1p(nashville_data['SalePrice'])\n",
        "\n",
        "# Drop irrelevant columns\n",
        "nashville_data = nashville_data.drop(['SaleDate', 'OwnerName'], axis=1)\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "nashville_data = pd.get_dummies(nashville_data, columns=['LandUse', 'SoldAsVacant'], drop_first=True)\n",
        "\n",
        "# Select high-correlation features\n",
        "selected_features = ['TotalValue', 'LandValue', 'BuildingValue', 'FullBath', 'Bedrooms', 'Acreage']\n",
        "X = nashville_data[selected_features].values\n",
        "y = nashville_data['SalePrice'].values\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build the ANN model with a smaller learning rate for stability\n",
        "ann = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=16, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1, activation='linear')\n",
        "])\n",
        "\n",
        "ann.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "ann.fit(X_train, y_train, batch_size=32, epochs=50, callbacks=[early_stopping])\n",
        "\n",
        "# Predict and apply inverse transformation if log-transformed\n",
        "raw_predictions = ann.predict(X_test)\n",
        "predictions = np.expm1(raw_predictions)  # Use np.expm1 if SalePrice was log-transformed\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "test_loss, test_mae = ann.evaluate(X_test, y_test)\n",
        "print(f\"Test MAE: {test_mae}\")\n",
        "\n",
        "# Revert log transformation on predictions to get actual prices\n",
        "predictions = np.expm1(ann.predict(X_test))\n",
        "\n",
        "# Display a few predictions alongside actual values\n",
        "for i in range(5):\n",
        "    print(f\"Predicted: {predictions[i][0]:.2f}, Actual: {np.expm1(y_test[i]):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni950MY3aQmD",
        "outputId": "2a08c0e0-d35e-43eb-d6e1-be459bcea292"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.1538 - mae: 0.7685\n",
            "Test MAE: 0.7575606107711792\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Predicted: 214281.83, Actual: 339000.00\n",
            "Predicted: 92094.12, Actual: 139900.00\n",
            "Predicted: 74330.88, Actual: 135000.00\n",
            "Predicted: 118240.88, Actual: 882700.00\n",
            "Predicted: 91280.58, Actual: 200000.00\n"
          ]
        }
      ]
    }
  ]
}